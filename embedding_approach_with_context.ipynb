{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csabi0312/DeepLProject/blob/main/embedding_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBl7tf1gcmg-"
      },
      "source": [
        "#Packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu sentence-transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZNd4W_JmbHp",
        "outputId": "8ef87af3-31ba-4e39-87e2-6347f238259a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mLalvIHcot_"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "\n",
        "\n",
        "# Setting the random seed\n",
        "seed_value = 42\n",
        "random.seed(seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ9DHwB1cpLX"
      },
      "source": [
        "#Data manipulations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "KO38DHN4EWCy",
        "outputId": "2e319aca-2080-4d32-edd5-05717d5feec8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               prompt  \\\n",
              "id                                                      \n",
              "0   Which of the following statements accurately d...   \n",
              "1   Which of the following is an accurate definiti...   \n",
              "2   Which of the following statements accurately d...   \n",
              "3   What is the significance of regularization in ...   \n",
              "4   Which of the following statements accurately d...   \n",
              "\n",
              "                                                    A  \\\n",
              "id                                                      \n",
              "0   MOND is a theory that reduces the observed mis...   \n",
              "1   Dynamic scaling refers to the evolution of sel...   \n",
              "2   The triskeles symbol was reconstructed as a fe...   \n",
              "3   Regularizing the mass-energy of an electron wi...   \n",
              "4   The angular spacing of features in the diffrac...   \n",
              "\n",
              "                                                    B  \\\n",
              "id                                                      \n",
              "0   MOND is a theory that increases the discrepanc...   \n",
              "1   Dynamic scaling refers to the non-evolution of...   \n",
              "2   The triskeles symbol is a representation of th...   \n",
              "3   Regularizing the mass-energy of an electron wi...   \n",
              "4   The angular spacing of features in the diffrac...   \n",
              "\n",
              "                                                    C  \\\n",
              "id                                                      \n",
              "0   MOND is a theory that explains the missing bar...   \n",
              "1   Dynamic scaling refers to the evolution of sel...   \n",
              "2   The triskeles symbol is a representation of a ...   \n",
              "3   Regularizing the mass-energy of an electron wi...   \n",
              "4   The angular spacing of features in the diffrac...   \n",
              "\n",
              "                                                    D  \\\n",
              "id                                                      \n",
              "0   MOND is a theory that reduces the discrepancy ...   \n",
              "1   Dynamic scaling refers to the non-evolution of...   \n",
              "2   The triskeles symbol represents three interloc...   \n",
              "3   Regularizing the mass-energy of an electron wi...   \n",
              "4   The angular spacing of features in the diffrac...   \n",
              "\n",
              "                                                    E  answer  \n",
              "id                                                             \n",
              "0   MOND is a theory that eliminates the observed ...       3  \n",
              "1   Dynamic scaling refers to the evolution of sel...       0  \n",
              "2   The triskeles symbol is a representation of th...       0  \n",
              "3   Regularizing the mass-energy of an electron wi...       2  \n",
              "4   The angular spacing of features in the diffrac...       3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1569db6-9055-4f98-8462-f96b4d5f466a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Which of the following statements accurately d...</td>\n",
              "      <td>MOND is a theory that reduces the observed mis...</td>\n",
              "      <td>MOND is a theory that increases the discrepanc...</td>\n",
              "      <td>MOND is a theory that explains the missing bar...</td>\n",
              "      <td>MOND is a theory that reduces the discrepancy ...</td>\n",
              "      <td>MOND is a theory that eliminates the observed ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Which of the following is an accurate definiti...</td>\n",
              "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
              "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
              "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
              "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
              "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Which of the following statements accurately d...</td>\n",
              "      <td>The triskeles symbol was reconstructed as a fe...</td>\n",
              "      <td>The triskeles symbol is a representation of th...</td>\n",
              "      <td>The triskeles symbol is a representation of a ...</td>\n",
              "      <td>The triskeles symbol represents three interloc...</td>\n",
              "      <td>The triskeles symbol is a representation of th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the significance of regularization in ...</td>\n",
              "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
              "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
              "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
              "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
              "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which of the following statements accurately d...</td>\n",
              "      <td>The angular spacing of features in the diffrac...</td>\n",
              "      <td>The angular spacing of features in the diffrac...</td>\n",
              "      <td>The angular spacing of features in the diffrac...</td>\n",
              "      <td>The angular spacing of features in the diffrac...</td>\n",
              "      <td>The angular spacing of features in the diffrac...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1569db6-9055-4f98-8462-f96b4d5f466a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1569db6-9055-4f98-8462-f96b4d5f466a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1569db6-9055-4f98-8462-f96b4d5f466a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e2101087-5e36-4888-8989-7626837eaf27\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e2101087-5e36-4888-8989-7626837eaf27')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e2101087-5e36-4888-8989-7626837eaf27 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#Loading the questions\n",
        "# Ez nem egy masik dataset, nem amit a mi kodunk csinal, csak tesztelni hasznalom hogy jo e a modell\n",
        "qna_df = pd.read_csv('https://raw.githubusercontent.com/emmermarcell/DeepLProject/main/train_with_context2.csv')\n",
        "\n",
        "# Creating a dictionary to map the values to numbers\n",
        "mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
        "\n",
        "# Replacing the values in the 'answer' column\n",
        "qna_df['answer'] = qna_df['answer'].replace(mapping)\n",
        "qna_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating  context column from wikipedia articles using the Faiss library"
      ],
      "metadata": {
        "id": "fj4mzmunKlHP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA54xrFajfQE",
        "outputId": "43e30c05-41c6-4aa8-cec3-7c6e50834017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "50\n",
            "50\n"
          ]
        }
      ],
      "source": [
        "#Train-Val-Test split:\n",
        "# Splitting the DataFrame into training, validation, and test datasets with a 2:1:1 ratio\n",
        "train, temp = train_test_split(qna_df, test_size=0.5, random_state=42)\n",
        "val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(len(train))\n",
        "print(len(val))\n",
        "print(len(test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gChAdoCCKiGN"
      },
      "source": [
        "The following code snippet acquires embeddings for the questions and possible answers using sciBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnPlDITGKiGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2ea42c-0729-4bf7-9a06-b8260ef2b9b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum Sequence Length: 512\n"
          ]
        }
      ],
      "source": [
        "# Load the SciBERT tokenizer and model\n",
        "model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "bert_model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "max_sequence_length = config.max_position_embeddings\n",
        "print(f\"Maximum Sequence Length: {max_sequence_length}\")\n",
        "\n",
        "\n",
        "def get_embeddings(prompt, context, answers):\n",
        "    \"\"\"\n",
        "    Function to get embeddings for a prompt, context and its corresponding answers.\n",
        "    The function returns a tensor of shape (7, 768),\n",
        "    where 7 is the number of sentences (1 prompt + 1 context + 5 answers)\n",
        "    and 768 is the embedding dimension.\n",
        "    \"\"\"\n",
        "    # List to store embeddings\n",
        "    embeddings = []\n",
        "\n",
        "    # Get embedding for the question\n",
        "    prompt_embedding = get_embedding(prompt)\n",
        "    embeddings.append(prompt_embedding)\n",
        "\n",
        "    # Get embedding for the context\n",
        "    context_embedding = get_embedding(context)\n",
        "    embeddings.append(context_embedding)\n",
        "\n",
        "    # Get embeddings for each answer\n",
        "    for answer in answers:\n",
        "        answer_embedding = get_embedding(answer)\n",
        "        embeddings.append(answer_embedding)\n",
        "\n",
        "    # Return stacked embeddings\n",
        "    return torch.stack(embeddings)\n",
        "\n",
        "\n",
        "def get_embedding(text):\n",
        "    \"\"\"\n",
        "    Function to get embedding for a text. The function returns the second to\n",
        "    last hidden state of the token `[CLS]` for classification task.\n",
        "    :param text:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # Tokenization and padding\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=max_sequence_length)\n",
        "    with torch.no_grad():\n",
        "        # Model Inference (pass the text to the model)\n",
        "        outputs = bert_model(**inputs)\n",
        "    # Extract the second to last hidden state of the token `[CLS]` for classification task\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVEQtc7JKiGO"
      },
      "outputs": [],
      "source": [
        "def convert_dataframe_to_model_input(df: pd.DataFrame):\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # Get embeddings for prompts and answers\n",
        "    X = []\n",
        "    for _, row in df_copy.iterrows():\n",
        "        prompt = row['prompt']\n",
        "        context = row['context']\n",
        "        answers = [row['A'], row['B'], row['C'], row['D'], row['E']]\n",
        "\n",
        "        embeddings = get_embeddings(prompt, context, answers)\n",
        "        X.append(embeddings)\n",
        "\n",
        "    X = torch.stack(X)\n",
        "    X = X.view(-1, 7, 768)  # Reshape the tensor to the desired shape\n",
        "\n",
        "    # Convert PyTorch tensor to NumPy array\n",
        "    X_np = X.cpu().numpy()\n",
        "\n",
        "    # Making a categorical variable for the target\n",
        "    y = df['answer']\n",
        "    y_cat = to_categorical(y, 5)\n",
        "\n",
        "    return X_np, y_cat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = convert_dataframe_to_model_input(train)\n",
        "X_val, y_val = convert_dataframe_to_model_input(val)\n",
        "X_test, y_test = convert_dataframe_to_model_input(test)"
      ],
      "metadata": {
        "id": "QArMEVBKrI7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "errdxEocKiGO",
        "outputId": "54b63374-8fc4-49b9-b7e4-fe001d8a1008",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/7 [===>..........................] - ETA: 14s - loss: 1.7874 - accuracy: 0.1875\n",
            "Epoch 1: val_loss improved from inf to 2.57483, saving model to scibert_weights.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 3s 138ms/step - loss: 2.9585 - accuracy: 0.2200 - val_loss: 2.5748 - val_accuracy: 0.1600\n",
            "Epoch 2/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.7195 - accuracy: 0.4375\n",
            "Epoch 2: val_loss improved from 2.57483 to 1.80949, saving model to scibert_weights.h5\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 1.8164 - accuracy: 0.3500 - val_loss: 1.8095 - val_accuracy: 0.1800\n",
            "Epoch 3/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.2686 - accuracy: 0.5000\n",
            "Epoch 3: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 1.1106 - accuracy: 0.6000 - val_loss: 1.9142 - val_accuracy: 0.2400\n",
            "Epoch 4/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.7456 - accuracy: 0.8125\n",
            "Epoch 4: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.9747 - accuracy: 0.6000 - val_loss: 1.9323 - val_accuracy: 0.2000\n",
            "Epoch 5/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.8233 - accuracy: 0.8125\n",
            "Epoch 5: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.6737 - accuracy: 0.8200 - val_loss: 2.1603 - val_accuracy: 0.1800\n",
            "Epoch 6/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.6599 - accuracy: 0.8750\n",
            "Epoch 6: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.4797 - accuracy: 0.9200 - val_loss: 2.1129 - val_accuracy: 0.1400\n",
            "Epoch 7/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.4078 - accuracy: 0.9375\n",
            "Epoch 7: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.3899 - accuracy: 0.9700 - val_loss: 2.2247 - val_accuracy: 0.1800\n",
            "Epoch 8/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1959 - accuracy: 1.0000\n",
            "Epoch 8: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2946 - accuracy: 0.9900 - val_loss: 2.2001 - val_accuracy: 0.1800\n",
            "Epoch 9/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.2368 - accuracy: 1.0000\n",
            "Epoch 9: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.2341 - accuracy: 1.0000 - val_loss: 2.2701 - val_accuracy: 0.1800\n",
            "Epoch 10/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1473 - accuracy: 1.0000\n",
            "Epoch 10: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1850 - accuracy: 1.0000 - val_loss: 2.3373 - val_accuracy: 0.2400\n",
            "Epoch 11/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1692 - accuracy: 1.0000\n",
            "Epoch 11: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1517 - accuracy: 1.0000 - val_loss: 2.3824 - val_accuracy: 0.1600\n",
            "Epoch 12/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0897 - accuracy: 1.0000\n",
            "Epoch 12: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1288 - accuracy: 1.0000 - val_loss: 2.4250 - val_accuracy: 0.1600\n",
            "Epoch 13/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0941 - accuracy: 1.0000\n",
            "Epoch 13: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.1057 - accuracy: 1.0000 - val_loss: 2.4727 - val_accuracy: 0.1600\n",
            "Epoch 14/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0752 - accuracy: 1.0000\n",
            "Epoch 14: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 2.4968 - val_accuracy: 0.2000\n",
            "Epoch 15/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0716 - accuracy: 1.0000\n",
            "Epoch 15: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0767 - accuracy: 1.0000 - val_loss: 2.5078 - val_accuracy: 0.2200\n",
            "Epoch 16/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0681 - accuracy: 1.0000\n",
            "Epoch 16: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 2.5472 - val_accuracy: 0.1800\n",
            "Epoch 17/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0478 - accuracy: 1.0000\n",
            "Epoch 17: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 2.6473 - val_accuracy: 0.1800\n",
            "Epoch 18/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0566 - accuracy: 1.0000\n",
            "Epoch 18: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 2.6170 - val_accuracy: 0.1800\n",
            "Epoch 19/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 19: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 2.6324 - val_accuracy: 0.1800\n",
            "Epoch 20/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0392 - accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 2.6892 - val_accuracy: 0.1800\n",
            "Epoch 21/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0302 - accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 2.7385 - val_accuracy: 0.1800\n",
            "Epoch 22/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0316 - accuracy: 1.0000\n",
            "Epoch 22: val_loss did not improve from 1.80949\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 2.7099 - val_accuracy: 0.1800\n",
            "Epoch 22: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79639e9556f0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Define a simple ranking neural network using Keras\n",
        "input_layer = Input(shape=(7, 768))\n",
        "flatten_layer = Flatten()(input_layer)\n",
        "dense_1 = Dense(128, activation='relu')(flatten_layer)\n",
        "output_layer = Dense(5, activation='softmax')(dense_1)\n",
        "\n",
        "# Create the model\n",
        "ranker_model = Model(inputs=input_layer, outputs=output_layer)\n",
        "ranker_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Use appropriate optimizer and loss\n",
        "\n",
        "# Use early stopping to get the best valuation loss\n",
        "path_checkpoint = \"scibert_weights.h5\"\n",
        "es_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=20, verbose=1)\n",
        "\n",
        "# Use ModelCheckpoint without the 'options' argument\n",
        "modelckpt_callback = ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=path_checkpoint,\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        ")\n",
        "\n",
        "# Use tensorboard to visualize the learning\n",
        "tensorboard_callback = TensorBoard(log_dir=\"./logs\", write_graph=True, histogram_freq=1)\n",
        "\n",
        "# Train the model\n",
        "ranker_model.fit(X_train,\n",
        "                 y_train,\n",
        "                 validation_data=(X_val, y_val),\n",
        "                 epochs=100,\n",
        "                 batch_size=16,\n",
        "                 callbacks=[es_callback,\n",
        "                            modelckpt_callback,\n",
        "                            tensorboard_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY9cxmyVKiGQ"
      },
      "source": [
        "Calculating the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hglDUuV4KiGP",
        "outputId": "6f690336-a112-47b9-a06c-6d3f562af286",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n",
            "Accuracy of the best model is  0.26\n"
          ]
        }
      ],
      "source": [
        "# Load the best model\n",
        "ranker_model = load_model(path_checkpoint)\n",
        "\n",
        "# Predict and get top index for each prediction and calculate the models accuracy\n",
        "preds = ranker_model.predict(X_test)\n",
        "test_err = accuracy_score(tf.argmax(y_test, axis = 1),tf.argmax(preds, axis = 1))\n",
        "\n",
        "# possible values of outcomes:\n",
        "print('Accuracy of the best model is ', test_err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4525ya5KiGR"
      },
      "source": [
        "Calculating Mean Average Precision @ 3 (MAP@3), which is the used metric in the kaggle competition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HvYN_MrKiGR",
        "outputId": "85cfd289-bb92-43c4-d6d1-3992b74aa3dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@3: 0.43\n"
          ]
        }
      ],
      "source": [
        "top3_indices = np.argsort(preds, axis=1)[:, -3:][:, ::-1]\n",
        "\n",
        "# Convert categorical labels to indices\n",
        "y_true_indices = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate Mean Average Precision @ 3 (MAP@3)\n",
        "def map3(actual, predicted, k=3):\n",
        "\n",
        "    if len(predicted) > k:\n",
        "        predicted = predicted[:k]\n",
        "\n",
        "    score = 0.0\n",
        "    num_hits = 0.0\n",
        "\n",
        "    for i, p in enumerate(predicted):\n",
        "        if p == actual and p not in predicted[:i]:\n",
        "            num_hits += 1.0\n",
        "            score += num_hits / (i + 1.0)\n",
        "\n",
        "    if np.isnan(score) or np.isnan(num_hits):\n",
        "        return 0.0\n",
        "\n",
        "    return score\n",
        "\n",
        "map3_score = np.mean([map3(actual, predicted, k=3) for actual, predicted in zip(y_true_indices, top3_indices)])\n",
        "print(\"MAP@3:\", map3_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO\n",
        "- Improve the neural network architecture (avoid overfitting)\n",
        "- Improve the embedding extraction method\n",
        "- Try PCA"
      ],
      "metadata": {
        "id": "3MLQCi5LKpvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "* https://huggingface.co/datasets/graelo/wikipedia/viewer/20230601.en\n",
        "\n",
        "* https://www.kaggle.com/code/cdeotte/how-to-train-open-book-model-part-1/notebook\n",
        "\n",
        "* https://www.kaggle.com/code/cdeotte/how-to-train-open-book-model-part-2/input\n",
        "\n",
        "@inproceedings{beltagy-etal-2019-scibert,\n",
        "    title = \"SciBERT: A Pretrained Language Model for Scientific Text\",\n",
        "    author = \"Beltagy, Iz  and Lo, Kyle  and Cohan, Arman\",\n",
        "    booktitle = \"EMNLP\",\n",
        "    year = \"2019\",\n",
        "    publisher = \"Association for Computational Linguistics\",\n",
        "    url = \"https://www.aclweb.org/anthology/D19-1371\"\n",
        "}"
      ],
      "metadata": {
        "id": "K1APFuB2KEdT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_l4-YP4jM6Nk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}